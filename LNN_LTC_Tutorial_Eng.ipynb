{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60cb75e-2f75-412d-81b7-f99eb27b01e0",
   "metadata": {},
   "source": [
    "# Step-by-Step Guide to Building an LTC Liquid Neural Network from Scratch\n",
    "Pavel Nakaznenko, 2024\n",
    "\n",
    "[Liquid Time-Constant Networks on Arxiv](https://arxiv.org/abs/2006.04439)\n",
    "\n",
    "Acknowledgement: This tutorial is heavily based on the reference [LTCCell implementation](https://github.com/mlech26l/ncps/blob/master/ncps/torch/ltc_cell.py), thanks to the authors of LNN.\n",
    "\n",
    "[Telegram channel: ToShoSeti](https://t.me/toshoseti)\n",
    "\n",
    "## Disclaimer\n",
    "This tutorial is an attempt to familiarize myself with the LNN and how do they work. By no means that is an ideal implementation. \n",
    "For me it is a complex topic, so bugs and misunderstanding are likely. Please proceed at your own discretion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a788f-ca24-4f2b-9df0-28eea3d87d11",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b6116-3c0a-4635-95c4-128b0815747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a634a2-a50d-49a3-ac1a-8582c093c08b",
   "metadata": {},
   "source": [
    "## Implementing the RandomWiring Class\n",
    "The RandomWiring class is responsible for defining the connection architecture between neurons. It initializes random adjacency matrices for neuron connections and sensory inputs. Those are used as an arbitrary sparsity matrix later in LIFNeuralLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa25083-2ede-4ae6-9524-92244b0f872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWiring:\n",
    "    def __init__(self, input_dim, output_dim, neuron_count):\n",
    "        self.input_dim = input_dim  # Number of input features\n",
    "        self.output_dim = output_dim  # Number of output features\n",
    "        self.neuron_count = neuron_count  # Number of neurons in the layer\n",
    "        self.adjacency_matrix = np.random.uniform(0, 1, (neuron_count, neuron_count))  # Adjacency matrix for connections between neurons\n",
    "        self.sensory_adjacency_matrix = np.random.uniform(0, 1, (input_dim, neuron_count))  # Adjacency matrix for sensory inputs to neurons\n",
    "\n",
    "    def erev_initializer(self):\n",
    "        return np.random.uniform(-0.2, 0.2, (self.neuron_count, self.neuron_count))  # Initialize reversal potentials for neuron connections\n",
    "\n",
    "    def sensory_erev_initializer(self):\n",
    "        return np.random.uniform(-0.2, 0.2, (self.input_dim, self.neuron_count))  # Initialize reversal potentials for sensory inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd71ad-1c3e-4b90-ac96-8835bcba9a9a",
   "metadata": {},
   "source": [
    "## Implementing the LIFNeuronLayer Class\n",
    "The LIFNeuronLayer class models the behavior of a layer of Leaky Integrate-and-Fire neurons. It initializes neuron parameters and defines the forward pass for computing neuron states. LIF dynamics are described using ODE and during the forward pass we solve the states using Euler Explicit method, described in the original article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7938b8-4841-4b11-8072-3bd3bf593baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFNeuronLayer(nn.Module):\n",
    "    def __init__(self, wiring, ode_unfolds=12, epsilon=1e-8):\n",
    "        super(LIFNeuronLayer, self).__init__()\n",
    "        self.wiring = wiring  # Wiring object containing connection information\n",
    "        self.ode_unfolds = ode_unfolds  # Number of ODE solver iterations\n",
    "        self.epsilon = epsilon  # Small value to avoid division by zero\n",
    "        self.softplus = nn.Softplus()  # Softplus activation function\n",
    "\n",
    "        # Initialization ranges for parameters\n",
    "        GLEAK_MIN, GLEAK_MAX = 0.001, 1.0\n",
    "        VLEAK_MIN, VLEAK_MAX = -0.2, 0.2\n",
    "        CM_MIN, CM_MAX = 0.4, 0.6\n",
    "        W_MIN, W_MAX = 0.001, 1.0\n",
    "        SIGMA_MIN, SIGMA_MAX = 3, 8\n",
    "        MU_MIN, MU_MAX = 0.3, 0.8\n",
    "        SENSORY_W_MIN, SENSORY_W_MAX = 0.001, 1.0\n",
    "        SENSORY_SIGMA_MIN, SENSORY_SIGMA_MAX = 3, 8\n",
    "        SENSORY_MU_MIN, SENSORY_MU_MAX = 0.3, 0.8\n",
    "\n",
    "        # Initialize neuron parameters with random values within specified ranges\n",
    "        self.gleak = nn.Parameter(torch.rand(wiring.neuron_count) * (GLEAK_MAX - GLEAK_MIN) + GLEAK_MIN)\n",
    "        self.vleak = nn.Parameter(torch.rand(wiring.neuron_count) * (VLEAK_MAX - VLEAK_MIN) + VLEAK_MIN)\n",
    "        self.cm = nn.Parameter(torch.rand(wiring.neuron_count) * (CM_MAX - CM_MIN) + CM_MIN)\n",
    "        self.w = nn.Parameter(torch.rand(wiring.neuron_count, wiring.neuron_count) * (W_MAX - W_MIN) + W_MIN)\n",
    "        self.sigma = nn.Parameter(torch.rand(wiring.neuron_count, wiring.neuron_count) * (SIGMA_MAX - SIGMA_MIN) + SIGMA_MIN)\n",
    "        self.mu = nn.Parameter(torch.rand(wiring.neuron_count, wiring.neuron_count) * (MU_MAX - MU_MIN) + MU_MIN)\n",
    "        self.erev = nn.Parameter(torch.Tensor(wiring.erev_initializer()))\n",
    "        \n",
    "        # Initialize sensory parameters with random values within specified ranges\n",
    "        self.sensory_w = nn.Parameter(torch.rand(wiring.input_dim, wiring.neuron_count) * (SENSORY_W_MAX - SENSORY_W_MIN) + SENSORY_W_MIN)\n",
    "        self.sensory_sigma = nn.Parameter(torch.rand(wiring.input_dim, wiring.neuron_count) * (SENSORY_SIGMA_MAX - SENSORY_SIGMA_MIN) + SENSORY_SIGMA_MIN)\n",
    "        self.sensory_mu = nn.Parameter(torch.rand(wiring.input_dim, wiring.neuron_count) * (SENSORY_MU_MAX - SENSORY_MU_MIN) + SENSORY_MU_MIN)\n",
    "        self.sensory_erev = nn.Parameter(torch.Tensor(wiring.sensory_erev_initializer()))\n",
    "\n",
    "        # Sparsity masks (fixed, non-learnable) based on the wiring adjacency matrices\n",
    "        self.sparsity_mask = torch.Tensor(np.abs(wiring.adjacency_matrix))\n",
    "        self.sensory_sparsity_mask = torch.Tensor(np.abs(wiring.sensory_adjacency_matrix))\n",
    "\n",
    "    def forward(self, inputs, state, elapsed_time=1.0):\n",
    "        return self.ode_solver(inputs, state, elapsed_time)\n",
    "\n",
    "    def ode_solver(self, inputs, state, elapsed_time):\n",
    "        v_pre = state  # Previous state (voltage)\n",
    "\n",
    "        # Pre-compute the effects of the sensory neurons\n",
    "        sensory_activation = self.softplus(self.sensory_w) * self.sigmoid(inputs, self.sensory_mu, self.sensory_sigma)\n",
    "        sensory_activation = sensory_activation * self.sensory_sparsity_mask\n",
    "        sensory_reversal_activation = sensory_activation * self.sensory_erev\n",
    "\n",
    "        # Calculate the numerator and denominator for sensory inputs\n",
    "        w_numerator_sensory = torch.sum(sensory_reversal_activation, dim=1)\n",
    "        w_denominator_sensory = torch.sum(sensory_activation, dim=1)\n",
    "\n",
    "        # Calculate membrane capacitance over time\n",
    "        cm_t = self.softplus(self.cm) / (elapsed_time / self.ode_unfolds)\n",
    "\n",
    "        # Initialize weights for neuron connections\n",
    "        w_param = self.softplus(self.w)\n",
    "        for _ in range(self.ode_unfolds):\n",
    "            # Activation based on previous state\n",
    "            w_activation = w_param * self.sigmoid(v_pre, self.mu, self.sigma)\n",
    "            w_activation = w_activation * self.sparsity_mask\n",
    "            reversal_activation = w_activation * self.erev\n",
    "\n",
    "            # Calculate the numerator and denominator for neuron connections\n",
    "            w_numerator = torch.sum(reversal_activation, dim=1) + w_numerator_sensory\n",
    "            w_denominator = torch.sum(w_activation, dim=1) + w_denominator_sensory\n",
    "\n",
    "            # Leak conductance and voltage calculations\n",
    "            gleak = self.softplus(self.gleak)\n",
    "            numerator = cm_t * v_pre + gleak * self.vleak + w_numerator\n",
    "            denominator = cm_t + gleak + w_denominator\n",
    "\n",
    "            # Update the state (voltage)\n",
    "            v_pre = numerator / (denominator + self.epsilon)\n",
    "\n",
    "        return v_pre\n",
    "\n",
    "    def sigmoid(self, v_pre, mu, sigma):\n",
    "        v_pre = torch.unsqueeze(v_pre, -1)  # Unsqueeze to match dimensions\n",
    "        activation = sigma * (v_pre - mu)  # Apply sigma and mean shift\n",
    "        return torch.sigmoid(activation)  # Apply sigmoid activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d292f2-b406-49e9-b857-c5e445abe57d",
   "metadata": {},
   "source": [
    "### Understanding the LIF Neural Layer\n",
    "\n",
    "The Leaky Integrate-and-Fire (LIF) neuron is a simple and widely used model in computational neuroscience. It simulates how biological neurons integrate incoming signals and fire when a threshold is reached. The LIF model captures the essential features of real neurons and is computationally efficient.\n",
    "\n",
    "#### Mathematical Formulation of LIF Neurons\n",
    "\n",
    "The LIF neuron can be described by the following differential equation:\n",
    "\n",
    "$$\\tau_m \\frac{dV(t)}{dt} = -V(t) + R_m I(t)$$\n",
    "\n",
    "Where:\n",
    "- $V(t)$ is the membrane potential at time $t$.\n",
    "- $\\tau_m$ is the membrane time constant.\n",
    "- $R_m$ is the membrane resistance.\n",
    "- $I(t)$ is the input current at time $t$.\n",
    "\n",
    "When the membrane potential $V(t)$ reaches a certain threshold $V_{\\text{th}}$, the neuron fires an action potential (or spike), and $V(t)$ is reset to a lower value, often $V_{\\text{reset}}$.\n",
    "\n",
    "#### Implementation in the LIFNeuronLayer Class\n",
    "\n",
    "The `LIFNeuronLayer` class in our implementation simulates a layer of LIF neurons with specific parameters for the membrane potential, conductance, and input weights. Let's break down its components and their roles.\n",
    "\n",
    "##### Initialization\n",
    "\n",
    "The class initializes several parameters that control the behavior of the neurons, including:\n",
    "- **gleak**: Leak conductance.\n",
    "- **vleak**: Leak voltage.\n",
    "- **cm**: Membrane capacitance.\n",
    "- **w, sigma, mu**: Parameters for the weights and activation functions.\n",
    "- **erev**: Reversal potentials for neuron connections.\n",
    "- **sensory_w, sensory_sigma, sensory_mu, sensory_erev**: Parameters for sensory inputs.\n",
    "\n",
    "#### Reversal Activation\n",
    "\n",
    "- **Reversal Activation**: This represents the influence of synaptic reversal potentials on the membrane potential. In biological neurons, the reversal potential is the voltage at which a specific ion's net flow through the membrane is zero. Incorporating reversal potentials into the model helps simulate realistic synaptic interactions.\n",
    "- **Calculation**: It involves multiplying the activation by the reversal potential matrix, which influences the neuron's state update during the forward pass. This mechanism helps integrate the effects of excitatory and inhibitory synapses.\n",
    "\n",
    "##### Forward Pass and ODE Solver\n",
    "\n",
    "The forward pass of the `LIFNeuronLayer` involves solving the differential equation that governs the membrane potential dynamics. This is done using an iterative approach with multiple ODE unfolds.\n",
    "\n",
    "Hereâ€™s a simplified explanation:\n",
    "1. **Pre-compute Sensory Effects**: Calculate the sensory activation and reversal activation based on the input.\n",
    "2. **ODE Solver Loop**: Iteratively update the neuron states using the ODE solver. This involves computing activations, applying sparsity masks, and updating the voltage states.\n",
    "\n",
    "##### Sigmoid Function\n",
    "\n",
    "The classic sigmoid function scales the inputs to a range between 0 and 1, which is essential for the activation of neurons. It is used both for the neuron connections and the sensory inputs.\n",
    "The sigmoid function in the LIFNeuronLayer class is customized to include parameters mu (mean) and sigma (scale). This customized implementation allows for more flexible and controlled activation behavior compared to the classic torch.sigmoid. \n",
    "\n",
    "1. **Parameter `mu` (Mean Shift)**:\n",
    "   - The `mu` parameter shifts the input voltage (`v_pre`). This shift allows the activation function to be centered around different mean values.\n",
    "   - Mathematically, `v_pre - mu` shifts the input such that the midpoint (where the sigmoid is 0.5) is not necessarily zero but `mu`.\n",
    "\n",
    "2. **Parameter `sigma` (Scale)**:\n",
    "   - The `sigma` parameter scales the input voltage (`v_pre`). This scaling controls the steepness of the sigmoid function.\n",
    "   - Mathematically, `sigma * (v_pre - mu)` adjusts the slope of the sigmoid curve. A larger `sigma` makes the sigmoid steeper, while a smaller `sigma` makes it more gradual.\n",
    "\n",
    "The customized sigmoid function is used to provide greater flexibility in the neural network's activation dynamics. Here's why this flexibility is important:\n",
    "\n",
    "1. **Biological Realism**:\n",
    "   - Biological neurons do not have a fixed activation threshold or response curve. The response curve can shift and scale depending on various factors.\n",
    "   - By incorporating `mu` and `sigma`, we can simulate this variability, making the model more biologically plausible.\n",
    "\n",
    "2. **Improved Learning**:\n",
    "   - Neural networks can benefit from adaptive activation functions. Different layers or neurons might require different activation behaviors to learn complex patterns effectively.\n",
    "   - The parameters `mu` and `sigma` can be learned during training, allowing the network to adjust its activation functions dynamically.\n",
    "\n",
    "3. **Enhanced Control**:\n",
    "   - In some cases, having control over the activation function's mean and scale can improve the network's ability to handle different input ranges and distributions.\n",
    "   - This customization can lead to better convergence and performance in certain tasks, especially in those involving varied and complex input signals.\n",
    "\n",
    "#### Why Random Adjacency and Sparsity Masks?\n",
    "\n",
    "- **Random Adjacency Matrix**: This matrix defines the connections between neurons in a random manner, simulating the complex and non-regular connectivity found in biological neural networks. It introduces variability and complexity in the network, which can help in learning more diverse patterns.\n",
    "- **Sparsity Mask**: This mask ensures that only certain connections are active, enforcing sparsity in the network. Sparse connections mimic the brain's efficient wiring, where not every neuron is connected to every other neuron, reducing computational load and preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07a6d2-1493-4540-927a-268978f1a196",
   "metadata": {},
   "source": [
    "## Implementing the LTCCell Class\n",
    "The LTCCell class represents a single cell in the Liquid Time-Constant Recurrent Neural Network. It uses the LIFNeuronLayer to update neuron states.\n",
    "\n",
    "Note: we assume that the amount of neurons is always greater than the output dimmension, so we just trim them into outputs. Should that not be the case, feel free to use additional fully connected layer to project the hidden states into outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c20767-040b-4848-8ecf-efe85c009908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTCCell(nn.Module):\n",
    "    def __init__(self, wiring, in_features=None, ode_unfolds=6, epsilon=1e-8):\n",
    "        super(LTCCell, self).__init__()        \n",
    "        self.wiring = wiring  # Wiring object\n",
    "        self.ode_unfolds = ode_unfolds  # Number of ODE solver iterations\n",
    "        self.epsilon = epsilon  # Small value to avoid division by zero\n",
    "\n",
    "        self.neuron = LIFNeuronLayer(wiring, ode_unfolds, epsilon)  # Initialize LIFNeuron with the given wiring\n",
    "\n",
    "    def forward(self, inputs, states, elapsed_time=1.0):\n",
    "        next_state = self.neuron(inputs, states, elapsed_time)  # Compute the next state using the neuron model\n",
    "        outputs = next_state[:, :self.wiring.output_dim] # Map the state to the output dimensions\n",
    "        return outputs, next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcae71a-2f04-411d-8b41-483503761b01",
   "metadata": {},
   "source": [
    "## Implementing the LTCRNN Class\n",
    "The LTCRNN class constructs the recurrent neural network using multiple LTCCell instances. It processes sequences of inputs to produce sequences of outputs.\n",
    "\n",
    "Note: In this tutorial, the LTCRNN is supposed to be called one shot, for the whole sequence, hence the state initialization to zero in each forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf2844-d177-4945-a456-c766c7eb93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTCRNN(nn.Module):\n",
    "    def __init__(self, wiring, input_dim, hidden_dim, output_dim):\n",
    "        super(LTCRNN, self).__init__()\n",
    "        self.cell = LTCCell(wiring, in_features=input_dim)  # Initialize LTCCell with wiring and input dimension\n",
    "        self.hidden_dim = hidden_dim  # Number of hidden neurons\n",
    "        self.output_dim = output_dim  # Number of output neurons\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size, seq_len, _ = inputs.size()  # Get batch size and sequence length from input dimensions\n",
    "        \n",
    "        states = torch.zeros(batch_size, self.hidden_dim)  # Initialize hidden states with zeros\n",
    "            \n",
    "        outputs = []  # List to store outputs for each time step\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            output, states = self.cell(inputs[:, t, :], states)  # Compute output and next state for each time step\n",
    "            outputs.append(output)  # Append the output to the list\n",
    "\n",
    "        result = torch.stack(outputs, dim=1)  # Stack the outputs along the sequence dimension\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d2fc0-2ad6-40a9-b5b3-d6ce9c8cfc0e",
   "metadata": {},
   "source": [
    "## Generating Spiral Data\n",
    "We will generate a dataset of spiral trajectories to train and evaluate our model. The generate_spiral_data function creates synthetic data points forming a spiral pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2f4b6-53f8-44ea-b4e8-16e132a19d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spiral data\n",
    "def generate_spiral_data(num_points, num_turns, noise = 2):\n",
    "    theta = np.linspace(0, num_turns * 2 * np.pi, num_points)\n",
    "    z = np.linspace(0, 1, num_points)\n",
    "    r = z\n",
    "    x = r * np.sin(theta) + noise * np.random.randn(*theta.shape) / num_points\n",
    "    y = r * np.cos(theta) + noise * np.random.randn(*theta.shape) / num_points\n",
    "    return np.stack([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6eeb8-fece-479d-9a19-b247e7e68deb",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "Next, we set the hyperparameters and prepare the data for training. We define a training loop to train the model using the generated spiral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf55c7-e2b9-499b-b446-1478cc93b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 2 # Number of input dimensions\n",
    "hidden_dim = 8 # Number of hidden dimensions (number of neurons in LIFNeuralLayer)\n",
    "output_dim = 2 # Number of output dimensions\n",
    "num_points = 500 # Number of spiral points in dataset\n",
    "num_turns = 3 # Number of spiral turns\n",
    "learning_rate = 0.005\n",
    "num_epochs = 2000\n",
    "seq_len = 3 # Maximum length of the sample sequence\n",
    "batch_size = 32\n",
    "\n",
    "# Generate data\n",
    "data = generate_spiral_data(num_points, num_turns)\n",
    "all_inputs = data[:-1, :]\n",
    "all_targets = data[1:, :]\n",
    "\n",
    "# Prepare input and target sequences\n",
    "trajectory_count = max(1, len(all_inputs) - seq_len)\n",
    "train_inputs = [torch.FloatTensor(all_inputs[i:i + seq_len]) for i in range(trajectory_count)]\n",
    "train_targets = [torch.FloatTensor(all_targets[i:i + seq_len]) for i in range(trajectory_count)]\n",
    "\n",
    "# Shuffle and split the data for training\n",
    "random_train_indices = np.arange(len(train_inputs))\n",
    "np.random.shuffle(random_train_indices)\n",
    "train_split_index = int(len(random_train_indices) * 0.8)\n",
    "random_train_indices = random_train_indices[:train_split_index]\n",
    "\n",
    "# Function to create batches\n",
    "def create_batches(data_list, batch_size):\n",
    "    return [data_list[i:i + batch_size] for i in range(0, len(data_list), batch_size)]\n",
    "\n",
    "# Create input and target batches\n",
    "train_input_batches = create_batches(train_inputs, batch_size)\n",
    "train_target_batches = create_batches(train_targets, batch_size)\n",
    "\n",
    "# Initialize model\n",
    "wiring = RandomWiring(input_dim, output_dim, hidden_dim)\n",
    "model = LTCRNN(wiring, input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()    \n",
    "    total_loss = 0\n",
    "\n",
    "    # Iterate over batches\n",
    "    for x, y_target in zip(train_input_batches, train_target_batches):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.stack(x)  # Stack batch of sequences\n",
    "        y_target = torch.stack(y_target)  # Stack batch of targets\n",
    "        outputs = model(x)  # Forward pass through the model\n",
    "        loss = criterion(outputs, y_target)  # Compute loss\n",
    "\n",
    "        # Accumulate total loss and perform backward pass and optimization step\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss every 100 epochs and plot predictions\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        # Prediction and plotting\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(torch.FloatTensor(all_inputs).unsqueeze(0))\n",
    "            np_predictions = predictions.squeeze(0).numpy()\n",
    "            val_loss = criterion(predictions, torch.FloatTensor(all_targets).unsqueeze(0))  # Compute loss\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Total train loss: {total_loss:.4f}, Total val loss: {val_loss:.4f}')\n",
    "\n",
    "        plt.plot(all_targets[:, 0], all_targets[:, 1], 'g-', label='True Path')\n",
    "        plt.plot(np_predictions[:, 0], np_predictions[:, 1], 'r-', label='Predicted Path')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83619c-a4db-4c24-8848-82bcd300a71c",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "In this tutorial we have implemented a classic LTC LNN as described in the original whitepaper. \n",
    "\n",
    "There are further imporvements available to the LNN architecture. \n",
    "\n",
    "Such as: \n",
    "* [Closed-form Continuous-Time Network models](https://arxiv.org/abs/2106.13898)\n",
    "* [LTC-SE](https://arxiv.org/abs/2304.08691)\n",
    "* [Liquid-S4](https://arxiv.org/abs/2209.12951)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae93978-0b3d-4ab9-9a5c-6f6299e96576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
